import numpy as np
from .plot import Plot
from .utils import load_posteriors, create_templates


class Validation:
    """
    Internal class for performing validation on the univariate and/or multivariate posterior PDFs of the test samples
    generated by the trained model.

    The marginal PDFs are validated using the framework developed by Gneiting et al. (2007)
    (https://hal.archives-ouvertes.fr/file/index/docid/363242/filename/jrssb1b.pdf).
    The multivariate PDFs are validated using the multivariate extension of the framework developed by
    Ziegel and Gneiting. (2014) (https://projecteuclid.org/download/pdfview_1/euclid.ejs/1418313582).

    Parameters
    ----------
    y_test: array_like
        An array of target features of testing galaxies with the same shape as y_train.

    target_features: list
        A list of variables of target features.

    path: str
        Location of the model directory.
    """

    def __init__(self, y_test, target_features, path):

        # Initialise arguments
        self.y_test = y_test
        self.path = path
        self.target_features = target_features
        self.posteriors = []
        self.no_features = len(target_features)
        self.no_points = 100
        self.posterior_folder = 'posteriors/'
        self.validation_folder = 'validation/'

        if self.y_test is not None:
            self.no_samples = self.y_test.shape[0]

        # Initialise classes
        self.plot = Plot(y_test=self.y_test, target_features=self.target_features, path=self.path)

    def validate(self, make_plots=False):
        """Top-level function for performing all modes of validation."""

        if self.y_test is None:
            print('Pass in y_test to perform validation.')
            exit()

        # Load posteriors
        self.posteriors = load_posteriors(path=self.path)

        # Run validation
        self.probabilistic_calibration()
        self.marginal_calibration()
        if make_plots:
            self.plot.plot_pit()
            self.plot.plot_marginal_calibration()

        if self.no_features > 1:
            pred_cdf_full, true_cdf_full = self.probabilistic_copula_calibration()
            self.kendall_calibration(pred_cdf_full, true_cdf_full)
            if make_plots:
                self.plot.plot_coppit()
                self.plot.plot_kendall_calibration()

        print('Saved validation. Any previously saved validation has been overwritten.')

    def probabilistic_calibration(self):
        """Performs probabilistic calibration"""

        pits = np.empty((self.no_samples, self.no_features))

        for feature in np.arange(self.no_features):
            for sample in np.arange(self.no_samples):
                posterior = np.array(self.posteriors[sample])
                pits[sample, feature] = np.sum(posterior[:, feature] <= self.y_test[sample, feature]) / posterior.shape[0]

        print('Completed probabilistic calibration.')
        np.save(self.path + self.validation_folder + 'pits.npy', pits)

    def marginal_calibration(self):
        """Performs marginal calibration"""

        marginal_calibration = np.empty((self.no_points, self.no_features))

        for feature in np.arange(self.no_features):
            count = 0
            min_, max_ = [np.floor(np.min(self.y_test[:, feature])), np.ceil(np.max(self.y_test[:, feature]))]

            for point in np.linspace(min_, max_, self.no_points):
                sum_ = np.zeros(self.no_samples)
                for sample in np.arange(self.no_samples):
                    posterior = np.array(self.posteriors[sample])
                    sum_[sample] = np.sum(posterior[:, feature] <= point) / posterior.shape[0]

                pred_cdf_marg_point = np.sum(sum_) / self.no_samples
                true_cdf_marg_point = np.sum(self.y_test[:, feature] <= point) / self.no_samples
                marginal_calibration[count, feature] = pred_cdf_marg_point - true_cdf_marg_point
                count += 1

        np.save(self.path + self.validation_folder + 'marginal_calibration.npy', marginal_calibration)
        print('Completed marginal calibration.')

    def probabilistic_copula_calibration(self):
        """Performs probabilistic copula calibration"""

        # Creating a list of list containing pred_cdf of each point in predictions
        pred_cdf_full = [[] for i in np.arange(self.no_samples)]
        true_cdf_full = []
        coppits = np.empty(self.no_samples)
        template_pred, template_true, template_same = create_templates(no_features=self.no_features)

        for sample in np.arange(self.no_samples):
            posterior = np.array(self.posteriors[sample])
            no_preds = posterior.shape[0]

            for pred in np.arange(no_preds):
                # For point at edges, if <= used, then point counts and cdf is never 0.
                # If <= is used, a large number of point will have near 0 probability, as a result, there will
                # be a peak at 0.
                # -1 insures, the point in consideration does not count when determining cdf.
                same_preds = np.sum(eval(template_same))
                pred_cdf_full[sample].append(np.sum(eval(template_pred)) / (no_preds - same_preds))

            true_cdf_full.append(np.sum(eval(template_true)) / no_preds)
            coppits[sample] = np.sum(pred_cdf_full[sample] <= true_cdf_full[sample]) / no_preds

        np.save(self.path + self.validation_folder + 'coppits.npy', coppits)
        print('Completed probabilistic copula calibration')

        return pred_cdf_full, true_cdf_full

    def kendall_calibration(self, pred_cdf_full, true_cdf_full):
        """Performs kendall calibration"""

        kendall_calibration = np.empty(self.no_points)
        count = 0

        for point in np.linspace(0, 1, self.no_points):
            sum_ = np.zeros(self.no_samples)
            for sample in np.arange(self.no_samples):
                sum_[sample] = np.sum(pred_cdf_full[sample] <= point) / len(pred_cdf_full[sample])

            kendall_func_point = np.sum(sum_) / self.no_samples
            true_cdf_point = np.sum(true_cdf_full <= point) / self.no_samples
            kendall_calibration[count] = kendall_func_point - true_cdf_point
            count += 1

        np.save(self.path + self.validation_folder + 'kendall_calibration.npy', kendall_calibration)
        print('Completed kendall calibration')
